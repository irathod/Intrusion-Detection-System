# -*- coding: utf-8 -*-
"""cs assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u7N-zwj65gmyw2CRSs-_RXsH1KvazypY
"""

# ================================
# Complete NSL-KDD IDS Notebook (Optimized)
# ================================

# Step 0: Install dependencies
!pip install pandas scikit-learn imbalanced-learn matplotlib seaborn joblib shap --quiet

# Step 1: Import libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# Step 2: Load dataset (upload files to Colab first)
train = pd.read_csv("KDDTrain+.txt", header=None)
test  = pd.read_csv("KDDTest+.txt", header=None)

# Step 3: Assign column names
cols = [
 'duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent',
 'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root',
 'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login',
 'count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate',
 'diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',
 'dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',
 'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','label'
]

# Fix mismatch if extra column exists
if train.shape[1] > len(cols):
    cols.append('extra')  # extra dummy column

train.columns = cols
test.columns  = cols

# Drop extra column if exists
if 'extra' in train.columns:
    train = train.drop(columns=['extra'])
    test  = test.drop(columns=['extra'])

# Step 4: Combine train+test for preprocessing
df = pd.concat([train, test], ignore_index=True)

# Binary target: normal=0, attack=1
df['target'] = df['label'].apply(lambda x: 0 if x=='normal' else 1)

# One-hot encode categorical columns
cat_cols = ['protocol_type','service','flag']
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Convert any remaining object columns to numeric
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = pd.to_numeric(df[col], errors='coerce')

# Features and target
X = df.drop(columns=['label','target'])
y = df['target']

# Split back into original train/test
X_train, X_test = X.iloc[:len(train)], X.iloc[len(train):]
y_train, y_test = y.iloc[:len(train)], y.iloc[len(train):]

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test  = scaler.transform(X_test)

print("Preprocessing done. X_train shape:", X_train.shape)

# ================================
# Step 5: Baseline Random Forest
# ================================
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

print("=== Baseline Random Forest ===")
print(classification_report(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))

# ================================
# Step 6: Improved Random Forest with SMOTE + Hyperparameter Tuning (subset)
# ================================
# Use subset for faster SMOTE processing
subset_size = 20000
X_train_small = X_train[:subset_size]
y_train_small = y_train[:subset_size]

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train_small, y_train_small)

# Hyperparameter grid
param_dist = {
    'n_estimators':[100,200,300],
    'max_depth':[10,20,None],
    'min_samples_split':[2,5,10],
    'min_samples_leaf':[1,2,4]
}

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions=param_dist,
    n_iter=10,
    cv=cv,
    scoring='f1',
    n_jobs=-1,
    verbose=2
)

search.fit(X_res, y_res)
best_rf = search.best_estimator_

# Predictions
y_pred2 = best_rf.predict(X_test)
print("=== Improved Random Forest ===")
print(classification_report(y_test, y_pred2))
print("ROC AUC:", roc_auc_score(y_test, best_rf.predict_proba(X_test)[:,1]))

# ================================
# Step 7: Confusion Matrix Plot
# ================================
cm = confusion_matrix(y_test, y_pred2)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - Improved Model")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()